{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Logistic Regression \n",
    "在这个实验中，是以Logistic回归作为基础，将再次复习Logistic回归，对Logistic回归将有更深的理解。通过对比未进行正则化的Logistic回归与正则化的Logistic回归在相同数据集上的表现来理解正则化缓解过拟合现象的作用。\n",
    "注：本次实验不再给出理论结果，在你们的训练结果中需要看出加入正则项以后的结果变化。\n",
    "## 1. 导入Python库\n",
    "首先，我们导入这次实验所需要使用的Python库，以及辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 知识回顾--过拟合问题分析\n",
    "\n",
    "实际应用中容易出现过拟合，其原因则在于模型已经足够复杂，但是我们往往根本就不知道设计的模型的复杂程度是否刚好满足要求。\n",
    "\n",
    "这就需要我们去判断模型是否刚刚好，如何判断是否出现了过拟合或欠拟合呢？我们一般通过将数据分为3个部分，训练集(train set)，验证集(validation set)和测试集(test set)。所谓过拟合就是指模型的泛化能力不强，那么，我们就在验证集上测试模型的泛化能力。如下图所示，我们可以看到，过拟合的时候在验证集上表现不好(即泛化能力不强)。而对于欠拟合，往往在训练集上的表现就可以看出表现不好。\n",
    "![goodfit_overfit](images/goodfit_overfit.jpg)\n",
    "\n",
    "如何解决欠拟合和过拟合问题？  \n",
    "欠拟合(Large Bias)： 增加模型的复杂度\n",
    "- 收集新的特征\n",
    "- 增加多项式组合特征   \n",
    "\n",
    "过拟合(Large Variance)\n",
    "- 增加数据(very effective, but not always practical)\n",
    "- 降低模型复杂度：\n",
    "    - 减少特征\n",
    "    - #### 正则化(Regularization)：非常有效的方法，可大幅度降低方差（增加偏差）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 可视化数据\n",
    "\n",
    "为了方便可视化，我们选用二维的数据方便观察。接下来，我们导入这次实验需要用到的数据，并且对其进行可视化。\n",
    "设$X$为我们的特征矩阵，$x^{(i)}$为训练集里面的第$i$个样本，$x_j$为样本中的第$j$个特征，则：  \n",
    "$$X=\\begin{bmatrix}x_1^{(1)} & x_2^{(1)} \\\\ x_1^{(2)} & x_2^{(2)} \\\\ \\vdots & \\vdots \\\\ x_1^{(m)} & x_2^{(m)} \\end{bmatrix}$$  \n",
    "$Y$为一个列向量，$y^{(i)}$代表第$i$个样本对应的标签，则：  \n",
    "$$Y=\\begin{bmatrix}y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}$$  \n",
    "\n",
    "这里我们已经将数据分成训练集(对应train.txt)和验证集(对应val.txt)。下面直观地观察一下训练集的数据分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: (153, 2)\n",
      "The shape of Y_train is: (153,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'E:\\\\anaconda\\\\Lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = np.loadtxt('train.txt')\n",
    "val_data = np.loadtxt('val.txt')\n",
    "X_train = train_data[:, 0:2].reshape(-1,2)\n",
    "Y_train = train_data[:, 2]\n",
    "X_val = val_data[:, 0:2].reshape(-1,2)\n",
    "Y_val = val_data[:, 2]\n",
    "\n",
    "print(\"The shape of X_train is:\", X_train.shape)\n",
    "print(\"The shape of Y_train is:\", Y_train.shape)\n",
    "\n",
    "plotData(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logistic与Regularized Logistic\n",
    "现在的任务是使用Logistic对上面的数据集进行分类。根据2中分析，我们可以知道特征较少往往就不能很好拟合数据，而这里只有两个特征，所以这里我们先使用多项式来组合特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 特征映射\n",
    "\n",
    "上面的数据只有两个特征，$x_1$和$x_2$，我们按照作业1里多项式回归的相同步骤，将$x_1$和$x_2$映射为最高为6次的多项式。即：\n",
    "$$mapFeature(x_1,x_2)=\\begin{bmatrix}1 \\\\ x_1 \\\\ x_2 \\\\ x_1^2 \\\\ x_1x_2 \\\\ x_2^2 \\\\ \\vdots \\\\ x_1x_2^5 \\\\ x_2^6 \\end{bmatrix}$$  \n",
    "这里第一维的*1*同作业1线性回归里一样为了方便处理偏置项，将两个特征映射成了$2+3+ \\dots +7=27$个特征。算上*1*则多项式回归的参数个数为$28$个。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After mapping the features, the shape of map_X_train is: (153, 28)\n",
      "X_train[3] [ 0.13 -0.16]\n",
      "map_X_train[3] [ 1.0000000e+00  1.3000000e-01 -1.6000000e-01  1.6900000e-02\n",
      " -2.0800000e-02  2.5600000e-02  2.1970000e-03 -2.7040000e-03\n",
      "  3.3280000e-03 -4.0960000e-03  2.8561000e-04 -3.5152000e-04\n",
      "  4.3264000e-04 -5.3248000e-04  6.5536000e-04  3.7129300e-05\n",
      " -4.5697600e-05  5.6243200e-05 -6.9222400e-05  8.5196800e-05\n",
      " -1.0485760e-04  4.8268090e-06 -5.9406880e-06  7.3116160e-06\n",
      " -8.9989120e-06  1.1075584e-05 -1.3631488e-05  1.6777216e-05]\n"
     ]
    }
   ],
   "source": [
    "map_X_train = mapFeature(X_train[:,0], X_train[:,1], degree=6)\n",
    "print(\"After mapping the features, the shape of map_X_train is:\", map_X_train.shape)\n",
    "\n",
    "print(\"X_train[3]\",X_train[3,:2])\n",
    "print(\"map_X_train[3]\",map_X_train[3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 sigmoid函数\n",
    "我们打算使用Logistic回归训练一个模型，来区分我们的正类与负类，因此我们需要一个Sigmoid函数：  \n",
    "$$sigmoid(z) = \\frac{1}{1+e^{-z}}$$\n",
    "**注意**：我们写的Sigmoid函数是需要能够对矩阵直接进行操作的。  \n",
    "**Hint**：计算$e^{-z}$可以使用np.exp(-z)来进行计算  \n",
    "**任务1**：实现sigmoid函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    对矩阵z中每个元素计算其Sigmoid函数值\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    g = None\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigmoid(map_X_train[1, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 初始化参数\n",
    "我们简单地权重$\\theta$初始化为零向量。  \n",
    "$$\\theta = \\begin{bmatrix}\\theta_1 \\\\ \\theta_2 \\\\ \\vdots \\\\ \\theta_n \\end{bmatrix} $$  \n",
    "其中$n$为特征的数量。  \n",
    "**Hint**：使用np.zeros()  \n",
    "**任务2**：初始化权重$\\theta$为零向量。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameter(n):\n",
    "    \"\"\"\n",
    "    初始化参数\n",
    "    :param n : map_X_train的列数\n",
    "    :return :权重向量\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    initial_theta = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return initial_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The initialized theta's shape is:\",init_parameter(map_X_train.shape[1]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 预测与计算loss\n",
    "\n",
    "没有正则项的loss:\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m}{[y^{(i)}log(h_{\\theta}(x^{(i)}))+(1-y^{(i)})log(1-h_{\\theta}(x^{(i)}))]}$$ \n",
    "其中，$$h_\\theta(X)=g(X\\theta)\\\\ g(z) = sigmoid(z)$$\n",
    "加入正则项的loss:\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m}{[y^{(i)}log(h_{\\theta}(x^{(i)}))+(1-y^{(i)})log(1-h_{\\theta}(x^{(i)}))]}+\\frac{\\lambda}{2m}\\sum_{j=1}^{n}{\\theta_{j}^2}$$  \n",
    "其中，$\\frac{\\lambda}{2m}\\sum_{j=1}^{n}{\\theta_{j}^2}$是正则化项。  \n",
    "我们从上式中看到，将$\\lambda$设置为$0$就可以将有正则项的loss转化为无正则项的loss。因此我们可以来设置$\\lambda$观察有正则和无正则的效果。  \n",
    "\n",
    "预测的时候对于有无正则项都是一样的。\n",
    "$$\n",
    "h_{\\theta}(x^{(i)}) \\ge 0.5 \\Rightarrow 为1类 \\\\\n",
    "h_{\\theta}(x^{(i)}) \\lt 0.5 \\Rightarrow 为0类 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**:  \n",
    "`a = np.array([1,2,3,4])`  \n",
    "`a`的平均值为`a.mean()`或者用`a.sum()`除以`a`的个数。  \n",
    "`a = np.array([0.3,0.5,0.8])` `a.round()`$\\rightarrow$ `[0., 0., 1.]`  \n",
    "其他一些函数可能会有用:`np.dot()`,`np.log()`,`np.power()`  \n",
    "**任务3**：完成计算loss的函数   \n",
    "注意：1.不要`for`循环求和。2.正则项loss不计算第一个权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, y, theta, lambd):\n",
    "    \"\"\"\n",
    "    计算loss\n",
    "    :param X:特征矩阵X\n",
    "    :param y:特征矩阵X对应的标签\n",
    "    :param theta:权重矩阵theta\n",
    "    :param lambd:正则化参数lambda\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    m = None       #数据的数量\n",
    "    h = None       #h函数\n",
    "    z = None       #正则化项\n",
    "    J = None       #J函数\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.array([0.1,0.2,0.3,0.4]).reshape(2,2)\n",
    "test_y = np.array([0,1])\n",
    "test_theta = np.array([0.5,0.6])\n",
    "test_lambd = 1\n",
    "print('test loss:',loss(test_X, test_y, test_theta, test_lambd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务4**：预测分类的函数  \n",
    "**Hint**: 可能有用的函数：round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    \"\"\"\n",
    "    对数据矩阵预测类别\n",
    "    :param X:特征矩阵X\n",
    "    :param theta:权重矩阵theta\n",
    "    ：return 由 0.,1.组成的向量，维度应该与X.shape[0]一致\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    h = None\n",
    "    classes = None\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.array([-0.1,-0.2,-0.3,0.4]).reshape(2,2)\n",
    "test_theta = np.array([0.5,0.6])\n",
    "print('test predict:',predict(test_X, test_theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 计算梯度\n",
    "梯度计算公式如下(可以自己推导一下)：\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_0}= \\frac{1}{m}\\sum_{i=1}^{m}{(h_{\\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)}}\\qquad j=0$$  \n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j}=  \\big[\\frac{1}{m}\\sum_{i=1}^{m}{(h_{\\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}}\\big]+\\frac{\\lambda}{m}\\theta_{j} \\quad j\\in\\left\\{ 1,2,...n \\right\\}$$ \n",
    "为了方便，我们可以先对所有$\\theta$(包括$\\theta_0$)用下面的式子求梯度，然后再给$\\theta_0$的梯度减去$\\frac{\\lambda}{m}\\theta_0$  \n",
    "**任务5**：完成计算梯度的函数  \n",
    "**Hint**: 1. 矩阵`A`的转置为`A.T` 2. $\\theta$的维度与$\\frac{\\partial J(\\theta)}{\\partial \\theta}$的维度是一样的 3.矩阵的长宽，或者说向量中的元素个数，可以通过 $X.shape[0]$ 和 $X.shape[1]$ 获得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(X, y, theta, lambd):\n",
    "    \"\"\"\n",
    "    计算梯度\n",
    "    :param X:特征矩阵X\n",
    "    :param y:特征矩阵X对应的标签\n",
    "    :param theta:权重矩阵theta\n",
    "    :param lambd:正则化参数lambda\n",
    "    :return : 对theta的梯度，维度应该与theta一致\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    m = None\n",
    "    h = None\n",
    "    grad = None\n",
    "    grad[0] = None\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.array([0.1,0.2,0.3,0.4]).reshape(2,2)\n",
    "test_y = np.array([0,1])\n",
    "test_theta = np.array([0.5,0.6])\n",
    "test_lambd = 1\n",
    "print('test compute_grad:',compute_grad(test_X, test_y, test_theta, test_lambd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 更新参数\n",
    "更新参数还是使用梯度下降法。公式如下：\n",
    "$$\n",
    " \\theta := \\theta - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务6**：完成更新参数的函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pameter(theta, gradients, learning_rate):\n",
    "    \"\"\"\n",
    "    更新参数theta\n",
    "    :param theta:权重theta\n",
    "    :param gradients:梯度值\n",
    "    :param learning_rate:学习速率\n",
    "    :return:更新后的theta\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    theta = None\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.array([0.1,0.2,0.3,0.4]).reshape(2,2)\n",
    "test_y = np.array([0,1])\n",
    "test_theta = np.array([0.5,0.6])\n",
    "test_lambd = 1\n",
    "test_grad = compute_grad(test_X, test_y, test_theta, test_lambd)\n",
    "print('test update_pameter:',update_pameter(test_theta, test_grad, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 搭积木\n",
    "接下来，我们将上面的代码整合到我们的模型Model中，并且我们将记录下成本$J$的变化过程。  \n",
    "**任务7**：完成训练模型函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(X, y, theta, iteration=300000, learning_rate = 1, lambd = 0):\n",
    "    \"\"\"\n",
    "    Regulared Logistic Regression Model\n",
    "    :param X:输入X\n",
    "    :param y:标签Y\n",
    "    :param theta:参数theta\n",
    "    :param iteration:迭代次数\n",
    "    :param learning_rate:学习率\n",
    "    :param lambd:正则化参数lambda\n",
    "    :return:最终theta的值、theta的历史记录、loss的历史记录和精确度的历史记录\n",
    "    \"\"\"\n",
    "    theta_history = []\n",
    "    J_history = []\n",
    "    acc_history = []\n",
    "    for i in range(iteration):\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        gradients = None\n",
    "        theta = None\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        if i%10000==0:\n",
    "            J = loss(X, y, theta, lambd)\n",
    "            J_history.append(J)\n",
    "            pred = predict(X, theta)\n",
    "            acc_history.append((pred==y).mean())\n",
    "            theta_history.append(theta)\n",
    "    \n",
    "    return theta,theta_history, J_history, acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.训练模型与分析\n",
    "\n",
    "## 5.1 无正则项\n",
    "无正则项只需设置$\\lambda=0$即可，下面是无正则项时在训练集和验证集上的表现以及在训练集上的分类边界。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 特征映射\n",
    "map_X_train = mapFeature(X_train[:,0], X_train[:,1], degree=6)\n",
    "map_X_val = mapFeature(X_val[:,0], X_val[:,1], degree=6)\n",
    "# 2. 初始化参数\n",
    "theta = init_parameter(map_X_train.shape[1])\n",
    "# 3. 训练\n",
    "theta,theta_history, J_history, acc_history = Model(map_X_train, Y_train, theta, iteration=300000, learning_rate = 1, lambd = 0)\n",
    "# 4. 验证集上验证\n",
    "acc_val_history = []\n",
    "J_val_history = []\n",
    "for i in range(len(theta_history)):\n",
    "    acc_val = (predict(map_X_val, theta_history[i])==Y_val).mean()\n",
    "    acc_val_history.append(acc_val)\n",
    "    J_val = loss(map_X_val, Y_val, theta_history[i], 0)\n",
    "    J_val_history.append(J_val)\n",
    "# 5. 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 绘制分类边界\n",
    "plotDecisionBoundary(X_train, Y_train,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5.2 比较预测精确度\n",
    "plt.plot(acc_history,label='train')\n",
    "plt.plot(acc_val_history,label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 比较loss\n",
    "plt.plot(J_history,label='train')\n",
    "plt.plot(J_val_history,label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从训练过程中的分类精确度分析可知，随着训练次数增加，在训练集上的精确度会进一步提升，但是在验证集上的精确度有轻微的下降。  \n",
    "从训练过程中的loss分析可知，随着训练次数增加，在训练集上的loss会进一步降低，但是在验证集上的loss会有些发散。  \n",
    "这些都说明了训练的模型已经过拟合，需要降低模型复杂度来提高泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 有正则项\n",
    "这里设置$\\lambda=0.005$，可以再提交作业后尝试设置不同的值观察结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 特征映射\n",
    "map_X_train = mapFeature(X_train[:,0], X_train[:,1], degree=6)\n",
    "map_X_val = mapFeature(X_val[:,0], X_val[:,1], degree=6)\n",
    "# 2. 初始化参数\n",
    "theta = init_parameter(map_X_train.shape[1])\n",
    "# 3. 训练\n",
    "theta,theta_history, J_history, acc_history = Model(map_X_train, Y_train, theta, iteration=300000, learning_rate = 1, lambd = 0.005)\n",
    "# 4. 验证集上验证\n",
    "acc_val_history = []\n",
    "J_val_history = []\n",
    "for i in range(len(theta_history)):\n",
    "    acc_val = (predict(map_X_val, theta_history[i])==Y_val).mean()\n",
    "    acc_val_history.append(acc_val)\n",
    "    J_val = loss(map_X_val, Y_val, theta_history[i], 0)\n",
    "    J_val_history.append(J_val)\n",
    "# 5. 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 绘制分类边界\n",
    "plotDecisionBoundary(X_train, Y_train,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 比较预测精确度\n",
    "plt.plot(acc_history,label='train')\n",
    "plt.plot(acc_val_history,label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 5.3 比较loss\n",
    "plt.plot(J_history,label='train')\n",
    "plt.plot(J_val_history,label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比无正则项的实验结果，我们可以发现有正则项的模型明显提升了泛化能力，过拟合的现象大大减小。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 总结\n",
    "通过这次实验，我们能够直观的理解正则化对于缓解过拟合现象所起到的作用。在提交完作业后，你还可以试试不同的$\\lambda$值，观察决策边界的变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ea307f64f28ee5e082e49b3665309add68f7312938244f4050a2f009b4177f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
